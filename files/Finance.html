<!DOCTYPE HTML>
<html lang="bg">

<head>
    <link rel="stylesheet" href="../css/Finance.css">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <title>Machine Learning</title>
</head>

<body background="../pictures/Finance.jpg">

    <div class="content">
        <h1>Portfolio Management</h1>
        <p>
            The term “robo-advisor” was essentially unheard-of just five years ago, but it is now commonplace in the financial landscape. 
            <br>The term is misleading and doesn’t involve robots at all. Rather, robo-advisors (companies such as Betterment, Wealthfront, and others)
            <br> are algorithms built to calibrate a financial portfolio to the goals and risk tolerance of the user.
            <br>
            <br>Users enter their goals (for example, retiring at age 65 with $250,000.00 in savings), age, income, and current financial assets. 
            <br>The advisor (which would more accurately be referred to as an “allocator”)
            <br> then spreads investments across asset classes and financial instruments in order to reach the user’s goals.
    </div>

    <div class="content2">
        <h1>Fraud Detection</h1>
        <p>
            Combine more accessible computing power, internet becoming more commonly used, and an increasing amount of valuable company data being stored online,
            <br>and you have a “perfect storm” for data security risk. While previous financial fraud detection systems depended heavily on complex and robust sets of rules, 
            <br>modern fraud detection goes beyond following a checklist of risk factors – it actively learns and calibrates to new potential (or real) security threats.
            <br>
            <br>This is the place of machine learning in finance for fraud – but the same principles hold true for other data security problems.
            <br> Using machine learning, systems can detect unique activities or behaviors (“anomalies”) and flag them for security teams. 
            <br>The challenge for these systems is to avoid false-positives – situations where “risks” are flagged that were never risks in the first place. 
            <br>Here at TechEmergence we’ve interviewed half a dozen fraud and security AI executives,
            <br> all of whom seem convinced that given the incalculably high number of ways that security can be breached,
            <br> genuinely “learning” systems will be a necessity in the five to ten years ahead.
    </div>

</body>

</html>